# Evaluation Metrics

The models' performance is evaluated using three metrics:

### AUC-PR: 

This metric combines precision and recall into a single value, which can be useful when dealing with imbalanced datasets. The corresponding script (AUC-PR.py) calculates the AUC-PR and plots the precision-recall curve.

### F1 Score: 

This metric is a measure of a model's accuracy that considers both precision and recall. The corresponding script (f1.py) calculates the F1 score.

### AUC-ROC: 

This metric illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The corresponding script (AUC-ROC.py) calculates the AUC-ROC and plots the ROC curve.

These metrics provide different performance measures that can be used to understand how well the model is performing in recognizing racial segregation in historical photos.
